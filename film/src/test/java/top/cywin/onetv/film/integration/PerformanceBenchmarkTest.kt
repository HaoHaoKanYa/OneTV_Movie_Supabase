package top.cywin.onetv.film.integration

import android.content.Context
import android.util.Log
import io.mockk.mockk
import kotlinx.coroutines.*
import kotlinx.coroutines.test.runTest
import org.junit.Before
import org.junit.Test
import org.junit.Assert.*
import top.cywin.onetv.film.catvod.SpiderManager
import top.cywin.onetv.film.data.repository.FilmRepository
import top.cywin.onetv.film.optimization.PerformanceBenchmark
import top.cywin.onetv.film.optimization.BenchmarkDirection
import top.cywin.onetv.film.concurrent.ConcurrentUtils
import java.util.concurrent.atomic.AtomicInteger
import java.util.concurrent.atomic.AtomicLong
import kotlin.system.measureTimeMillis

/**
 * æ€§èƒ½åŸºå‡†æµ‹è¯•
 * 
 * åŸºäº FongMi/TV çš„æ€§èƒ½åŸºå‡†æµ‹è¯•å®ç°
 * æµ‹è¯•ç³»ç»Ÿå„ç»„ä»¶çš„æ€§èƒ½æŒ‡æ ‡å’ŒåŸºå‡†
 * 
 * åŠŸèƒ½ï¼š
 * - å“åº”æ—¶é—´åŸºå‡†æµ‹è¯•
 * - ååé‡åŸºå‡†æµ‹è¯•
 * - å†…å­˜ä½¿ç”¨åŸºå‡†æµ‹è¯•
 * - å¹¶å‘æ€§èƒ½åŸºå‡†æµ‹è¯•
 * - ç¼“å­˜æ€§èƒ½åŸºå‡†æµ‹è¯•
 * - ç½‘ç»œæ€§èƒ½åŸºå‡†æµ‹è¯•
 * - ç»¼åˆæ€§èƒ½åŸºå‡†æµ‹è¯•
 * 
 * @author OneTV Team
 * @since 2025-07-12
 */
class PerformanceBenchmarkTest {
    
    companion object {
        private const val TAG = "ONETV_FILM_PERFORMANCE_BENCHMARK"
        private const val TEST_TIMEOUT = 120000L // 2åˆ†é’Ÿ
        private const val WARMUP_ITERATIONS = 10
        private const val BENCHMARK_ITERATIONS = 100
        private const val CONCURRENT_USERS = 20
        private const val OPERATIONS_PER_USER = 50
    }
    
    private lateinit var context: Context
    private lateinit var spiderManager: SpiderManager
    private lateinit var filmRepository: FilmRepository
    
    // åŸºå‡†ç»“æœ
    private val benchmarkResults = mutableListOf<PerformanceBenchmark>()
    
    @Before
    fun setup() {
        context = mockk<Context>(relaxed = true)
        spiderManager = SpiderManager(context)
        filmRepository = spiderManager.getFilmRepository()
        
        Log.d(TAG, "ğŸ—ï¸ æ€§èƒ½åŸºå‡†æµ‹è¯•ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")
    }
    
    /**
     * â±ï¸ å“åº”æ—¶é—´åŸºå‡†æµ‹è¯•
     */
    @Test
    fun testResponseTimeBenchmark() = runTest(timeout = TEST_TIMEOUT) {
        Log.d(TAG, "â±ï¸ å¼€å§‹å“åº”æ—¶é—´åŸºå‡†æµ‹è¯•")
        
        // é¢„çƒ­
        repeat(WARMUP_ITERATIONS) {
            performResponseTimeOperation()
        }
        
        // åŸºå‡†æµ‹è¯•
        val responseTimes = mutableListOf<Long>()
        
        repeat(BENCHMARK_ITERATIONS) {
            val responseTime = measureTimeMillis {
                performResponseTimeOperation()
            }
            responseTimes.add(responseTime)
        }
        
        // è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        val avgResponseTime = responseTimes.average()
        val minResponseTime = responseTimes.minOrNull() ?: 0L
        val maxResponseTime = responseTimes.maxOrNull() ?: 0L
        val p50ResponseTime = responseTimes.sorted()[responseTimes.size / 2]
        val p95ResponseTime = responseTimes.sorted()[(responseTimes.size * 0.95).toInt()]
        val p99ResponseTime = responseTimes.sorted()[(responseTimes.size * 0.99).toInt()]
        
        Log.d(TAG, "å“åº”æ—¶é—´åŸºå‡†æµ‹è¯•ç»“æœ:")
        Log.d(TAG, "  å¹³å‡å“åº”æ—¶é—´: ${String.format("%.2f", avgResponseTime)}ms")
        Log.d(TAG, "  æœ€å°å“åº”æ—¶é—´: ${minResponseTime}ms")
        Log.d(TAG, "  æœ€å¤§å“åº”æ—¶é—´: ${maxResponseTime}ms")
        Log.d(TAG, "  P50å“åº”æ—¶é—´: ${p50ResponseTime}ms")
        Log.d(TAG, "  P95å“åº”æ—¶é—´: ${p95ResponseTime}ms")
        Log.d(TAG, "  P99å“åº”æ—¶é—´: ${p99ResponseTime}ms")
        
        // è®°å½•åŸºå‡†
        benchmarkResults.add(
            PerformanceBenchmark(
                name = "å¹³å‡å“åº”æ—¶é—´",
                category = "å“åº”æ—¶é—´",
                targetValue = 500.0, // ç›®æ ‡500ms
                currentValue = avgResponseTime,
                unit = "ms",
                direction = BenchmarkDirection.LOWER_IS_BETTER
            )
        )
        
        benchmarkResults.add(
            PerformanceBenchmark(
                name = "P95å“åº”æ—¶é—´",
                category = "å“åº”æ—¶é—´",
                targetValue = 1000.0, // ç›®æ ‡1ç§’
                currentValue = p95ResponseTime.toDouble(),
                unit = "ms",
                direction = BenchmarkDirection.LOWER_IS_BETTER
            )
        )
        
        // æ€§èƒ½æ–­è¨€
        assertTrue("å¹³å‡å“åº”æ—¶é—´åº”å°äº1ç§’", avgResponseTime < 1000.0)
        assertTrue("P95å“åº”æ—¶é—´åº”å°äº2ç§’", p95ResponseTime < 2000L)
        assertTrue("P99å“åº”æ—¶é—´åº”å°äº5ç§’", p99ResponseTime < 5000L)
        
        Log.d(TAG, "âœ… å“åº”æ—¶é—´åŸºå‡†æµ‹è¯•å®Œæˆ")
    }
    
    /**
     * ğŸ”„ å“åº”æ—¶é—´æµ‹è¯•æ“ä½œ
     */
    private suspend fun performResponseTimeOperation() {
        val operations = listOf(
            { filmRepository.getRepositoryStats() },
            { spiderManager.getConcurrentStats() },
            { spiderManager.getCacheStats() }
        )
        
        val operation = operations.random()
        operation()
    }
    
    /**
     * ğŸ“ˆ ååé‡åŸºå‡†æµ‹è¯•
     */
    @Test
    fun testThroughputBenchmark() = runTest(timeout = TEST_TIMEOUT) {
        Log.d(TAG, "ğŸ“ˆ å¼€å§‹ååé‡åŸºå‡†æµ‹è¯•")
        
        val testDuration = 30000L // 30ç§’
        val operationCount = AtomicLong(0)
        val errorCount = AtomicLong(0)
        
        val startTime = System.currentTimeMillis()
        val endTime = startTime + testDuration
        
        // å¹¶å‘æ‰§è¡Œæ“ä½œ
        val jobs = (1..CONCURRENT_USERS).map {
            async {
                while (System.currentTimeMillis() < endTime) {
                    try {
                        performThroughputOperation()
                        operationCount.incrementAndGet()
                    } catch (e: Exception) {
                        errorCount.incrementAndGet()
                    }
                    delay(10L) // çŸ­æš‚å»¶è¿Ÿé¿å…è¿‡åº¦æ¶ˆè€—èµ„æº
                }
            }
        }
        
        jobs.awaitAll()
        
        val actualDuration = System.currentTimeMillis() - startTime
        val totalOperations = operationCount.get()
        val totalErrors = errorCount.get()
        val throughput = totalOperations.toDouble() / (actualDuration / 1000.0)
        val errorRate = totalErrors.toDouble() / totalOperations
        
        Log.d(TAG, "ååé‡åŸºå‡†æµ‹è¯•ç»“æœ:")
        Log.d(TAG, "  æµ‹è¯•æ—¶é•¿: ${actualDuration}ms")
        Log.d(TAG, "  æ€»æ“ä½œæ•°: $totalOperations")
        Log.d(TAG, "  é”™è¯¯æ•°: $totalErrors")
        Log.d(TAG, "  ååé‡: ${String.format("%.2f", throughput)} ops/sec")
        Log.d(TAG, "  é”™è¯¯ç‡: ${String.format("%.2f%%", errorRate * 100)}")
        
        // è®°å½•åŸºå‡†
        benchmarkResults.add(
            PerformanceBenchmark(
                name = "ç³»ç»Ÿååé‡",
                category = "ååé‡",
                targetValue = 100.0, // ç›®æ ‡100 ops/sec
                currentValue = throughput,
                unit = "ops/sec",
                direction = BenchmarkDirection.HIGHER_IS_BETTER
            )
        )
        
        benchmarkResults.add(
            PerformanceBenchmark(
                name = "é”™è¯¯ç‡",
                category = "å¯é æ€§",
                targetValue = 0.01, // ç›®æ ‡1%
                currentValue = errorRate,
                unit = "%",
                direction = BenchmarkDirection.LOWER_IS_BETTER
            )
        )
        
        // æ€§èƒ½æ–­è¨€
        assertTrue("ååé‡åº”å¤§äº50 ops/sec", throughput > 50.0)
        assertTrue("é”™è¯¯ç‡åº”å°äº5%", errorRate < 0.05)
        
        Log.d(TAG, "âœ… ååé‡åŸºå‡†æµ‹è¯•å®Œæˆ")
    }
    
    /**
     * ğŸ”„ ååé‡æµ‹è¯•æ“ä½œ
     */
    private suspend fun performThroughputOperation() {
        val operations = listOf(
            {
                // ç¼“å­˜æ“ä½œ
                val cacheManager = spiderManager.getCacheManager()
                val key = "throughput_test_${System.nanoTime()}"
                cacheManager.put(key, "test_value")
                cacheManager.get(key, String::class.java)
            },
            {
                // å¹¶å‘æ“ä½œ
                val concurrentManager = spiderManager.getConcurrentManager()
                concurrentManager.executeWithTimeout(1000L) {
                    delay(1L)
                    "result"
                }
            },
            {
                // ç»Ÿè®¡æ“ä½œ
                filmRepository.getRepositoryStats()
            }
        )
        
        val operation = operations.random()
        operation()
    }
    
    /**
     * ğŸ§  å†…å­˜ä½¿ç”¨åŸºå‡†æµ‹è¯•
     */
    @Test
    fun testMemoryUsageBenchmark() = runTest(timeout = TEST_TIMEOUT) {
        Log.d(TAG, "ğŸ§  å¼€å§‹å†…å­˜ä½¿ç”¨åŸºå‡†æµ‹è¯•")
        
        val runtime = Runtime.getRuntime()
        
        // è®°å½•åˆå§‹å†…å­˜çŠ¶æ€
        val initialMemory = runtime.totalMemory() - runtime.freeMemory()
        
        // æ‰§è¡Œå†…å­˜å¯†é›†å‹æ“ä½œ
        val operations = mutableListOf<Any>()
        
        repeat(1000) {
            // åˆ›å»ºä¸€äº›å¯¹è±¡æ¥æ¨¡æ‹Ÿå†…å­˜ä½¿ç”¨
            operations.add(createMemoryTestObject())
        }
        
        // è®°å½•å³°å€¼å†…å­˜ä½¿ç”¨
        val peakMemory = runtime.totalMemory() - runtime.freeMemory()
        val memoryIncrease = peakMemory - initialMemory
        
        // æ¸…ç†å¯¹è±¡
        operations.clear()
        System.gc()
        delay(1000L) // ç­‰å¾…GCå®Œæˆ
        
        // è®°å½•æ¸…ç†åå†…å­˜
        val finalMemory = runtime.totalMemory() - runtime.freeMemory()
        val memoryRecovered = peakMemory - finalMemory
        val recoveryRate = memoryRecovered.toDouble() / memoryIncrease
        
        Log.d(TAG, "å†…å­˜ä½¿ç”¨åŸºå‡†æµ‹è¯•ç»“æœ:")
        Log.d(TAG, "  åˆå§‹å†…å­˜: ${String.format("%.2f", initialMemory / 1024.0 / 1024.0)}MB")
        Log.d(TAG, "  å³°å€¼å†…å­˜: ${String.format("%.2f", peakMemory / 1024.0 / 1024.0)}MB")
        Log.d(TAG, "  å†…å­˜å¢é•¿: ${String.format("%.2f", memoryIncrease / 1024.0 / 1024.0)}MB")
        Log.d(TAG, "  æœ€ç»ˆå†…å­˜: ${String.format("%.2f", finalMemory / 1024.0 / 1024.0)}MB")
        Log.d(TAG, "  å†…å­˜å›æ”¶: ${String.format("%.2f", memoryRecovered / 1024.0 / 1024.0)}MB")
        Log.d(TAG, "  å›æ”¶ç‡: ${String.format("%.1f%%", recoveryRate * 100)}")
        
        // è®°å½•åŸºå‡†
        benchmarkResults.add(
            PerformanceBenchmark(
                name = "å†…å­˜å›æ”¶ç‡",
                category = "å†…å­˜ç®¡ç†",
                targetValue = 0.8, // ç›®æ ‡80%
                currentValue = recoveryRate,
                unit = "%",
                direction = BenchmarkDirection.HIGHER_IS_BETTER
            )
        )
        
        // æ€§èƒ½æ–­è¨€
        assertTrue("å†…å­˜å›æ”¶ç‡åº”å¤§äº70%", recoveryRate > 0.7)
        
        Log.d(TAG, "âœ… å†…å­˜ä½¿ç”¨åŸºå‡†æµ‹è¯•å®Œæˆ")
    }
    
    /**
     * ğŸ”„ åˆ›å»ºå†…å­˜æµ‹è¯•å¯¹è±¡
     */
    private fun createMemoryTestObject(): Any {
        return mapOf(
            "id" to System.nanoTime(),
            "data" to ByteArray(1024), // 1KBæ•°æ®
            "timestamp" to System.currentTimeMillis(),
            "metadata" to mapOf(
                "type" to "test",
                "version" to "1.0",
                "description" to "Memory test object for benchmark"
            )
        )
    }
    
    /**
     * âš¡ å¹¶å‘æ€§èƒ½åŸºå‡†æµ‹è¯•
     */
    @Test
    fun testConcurrentPerformanceBenchmark() = runTest(timeout = TEST_TIMEOUT) {
        Log.d(TAG, "âš¡ å¼€å§‹å¹¶å‘æ€§èƒ½åŸºå‡†æµ‹è¯•")
        
        val concurrentManager = spiderManager.getConcurrentManager()
        val taskCount = 100
        val completedTasks = AtomicInteger(0)
        val failedTasks = AtomicInteger(0)
        val totalExecutionTime = AtomicLong(0)
        
        val startTime = System.currentTimeMillis()
        
        // å¹¶å‘æ‰§è¡Œä»»åŠ¡
        val tasks = (1..taskCount).map { taskId ->
            async {
                val taskStartTime = System.currentTimeMillis()
                try {
                    val result = concurrentManager.executeWithTimeout(5000L) {
                        delay(50L) // æ¨¡æ‹Ÿå·¥ä½œ
                        "Task $taskId result"
                    }
                    
                    val taskDuration = System.currentTimeMillis() - taskStartTime
                    totalExecutionTime.addAndGet(taskDuration)
                    
                    if (result != null) {
                        completedTasks.incrementAndGet()
                    } else {
                        failedTasks.incrementAndGet()
                    }
                } catch (e: Exception) {
                    failedTasks.incrementAndGet()
                }
            }
        }
        
        tasks.awaitAll()
        
        val totalTime = System.currentTimeMillis() - startTime
        val completed = completedTasks.get()
        val failed = failedTasks.get()
        val successRate = completed.toDouble() / taskCount
        val avgExecutionTime = if (completed > 0) totalExecutionTime.get() / completed else 0L
        val throughput = taskCount.toDouble() / (totalTime / 1000.0)
        
        Log.d(TAG, "å¹¶å‘æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœ:")
        Log.d(TAG, "  ä»»åŠ¡æ€»æ•°: $taskCount")
        Log.d(TAG, "  å®Œæˆä»»åŠ¡: $completed")
        Log.d(TAG, "  å¤±è´¥ä»»åŠ¡: $failed")
        Log.d(TAG, "  æˆåŠŸç‡: ${String.format("%.1f%%", successRate * 100)}")
        Log.d(TAG, "  å¹³å‡æ‰§è¡Œæ—¶é—´: ${avgExecutionTime}ms")
        Log.d(TAG, "  æ€»è€—æ—¶: ${totalTime}ms")
        Log.d(TAG, "  å¹¶å‘ååé‡: ${String.format("%.2f", throughput)} tasks/sec")
        
        // è®°å½•åŸºå‡†
        benchmarkResults.add(
            PerformanceBenchmark(
                name = "å¹¶å‘ä»»åŠ¡æˆåŠŸç‡",
                category = "å¹¶å‘æ€§èƒ½",
                targetValue = 0.95, // ç›®æ ‡95%
                currentValue = successRate,
                unit = "%",
                direction = BenchmarkDirection.HIGHER_IS_BETTER
            )
        )
        
        benchmarkResults.add(
            PerformanceBenchmark(
                name = "å¹¶å‘ååé‡",
                category = "å¹¶å‘æ€§èƒ½",
                targetValue = 50.0, // ç›®æ ‡50 tasks/sec
                currentValue = throughput,
                unit = "tasks/sec",
                direction = BenchmarkDirection.HIGHER_IS_BETTER
            )
        )
        
        // æ€§èƒ½æ–­è¨€
        assertTrue("å¹¶å‘ä»»åŠ¡æˆåŠŸç‡åº”å¤§äº90%", successRate > 0.9)
        assertTrue("å¹¶å‘ååé‡åº”å¤§äº20 tasks/sec", throughput > 20.0)
        
        Log.d(TAG, "âœ… å¹¶å‘æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ")
    }
    
    /**
     * ğŸ—„ï¸ ç¼“å­˜æ€§èƒ½åŸºå‡†æµ‹è¯•
     */
    @Test
    fun testCachePerformanceBenchmark() = runTest(timeout = TEST_TIMEOUT) {
        Log.d(TAG, "ğŸ—„ï¸ å¼€å§‹ç¼“å­˜æ€§èƒ½åŸºå‡†æµ‹è¯•")
        
        val cacheManager = spiderManager.getCacheManager()
        val operationCount = 1000
        val hitCount = AtomicInteger(0)
        val missCount = AtomicInteger(0)
        
        // é¢„å¡«å……ç¼“å­˜
        repeat(operationCount / 2) { i ->
            cacheManager.put("cache_test_$i", "value_$i")
        }
        
        val startTime = System.currentTimeMillis()
        
        // æ‰§è¡Œç¼“å­˜æ“ä½œ
        repeat(operationCount) { i ->
            val key = "cache_test_${i % (operationCount / 2)}"
            val value = cacheManager.get(key, String::class.java)
            
            if (value != null) {
                hitCount.incrementAndGet()
            } else {
                missCount.incrementAndGet()
            }
        }
        
        val totalTime = System.currentTimeMillis() - startTime
        val hits = hitCount.get()
        val misses = missCount.get()
        val hitRate = hits.toDouble() / operationCount
        val cacheOpsPerSecond = operationCount.toDouble() / (totalTime / 1000.0)
        
        Log.d(TAG, "ç¼“å­˜æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœ:")
        Log.d(TAG, "  æ“ä½œæ€»æ•°: $operationCount")
        Log.d(TAG, "  ç¼“å­˜å‘½ä¸­: $hits")
        Log.d(TAG, "  ç¼“å­˜æœªå‘½ä¸­: $misses")
        Log.d(TAG, "  å‘½ä¸­ç‡: ${String.format("%.1f%%", hitRate * 100)}")
        Log.d(TAG, "  æ€»è€—æ—¶: ${totalTime}ms")
        Log.d(TAG, "  ç¼“å­˜æ“ä½œé€Ÿåº¦: ${String.format("%.2f", cacheOpsPerSecond)} ops/sec")
        
        // è®°å½•åŸºå‡†
        benchmarkResults.add(
            PerformanceBenchmark(
                name = "ç¼“å­˜å‘½ä¸­ç‡",
                category = "ç¼“å­˜æ€§èƒ½",
                targetValue = 0.8, // ç›®æ ‡80%
                currentValue = hitRate,
                unit = "%",
                direction = BenchmarkDirection.HIGHER_IS_BETTER
            )
        )
        
        benchmarkResults.add(
            PerformanceBenchmark(
                name = "ç¼“å­˜æ“ä½œé€Ÿåº¦",
                category = "ç¼“å­˜æ€§èƒ½",
                targetValue = 1000.0, // ç›®æ ‡1000 ops/sec
                currentValue = cacheOpsPerSecond,
                unit = "ops/sec",
                direction = BenchmarkDirection.HIGHER_IS_BETTER
            )
        )
        
        // æ€§èƒ½æ–­è¨€
        assertTrue("ç¼“å­˜å‘½ä¸­ç‡åº”å¤§äº70%", hitRate > 0.7)
        assertTrue("ç¼“å­˜æ“ä½œé€Ÿåº¦åº”å¤§äº500 ops/sec", cacheOpsPerSecond > 500.0)
        
        Log.d(TAG, "âœ… ç¼“å­˜æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ")
    }
    
    /**
     * ğŸ“Š ç»¼åˆæ€§èƒ½åŸºå‡†æµ‹è¯•
     */
    @Test
    fun testOverallPerformanceBenchmark() = runTest(timeout = TEST_TIMEOUT) {
        Log.d(TAG, "ğŸ“Š å¼€å§‹ç»¼åˆæ€§èƒ½åŸºå‡†æµ‹è¯•")
        
        // æ‰§è¡Œæ‰€æœ‰åŸºå‡†æµ‹è¯•
        testResponseTimeBenchmark()
        testThroughputBenchmark()
        testMemoryUsageBenchmark()
        testConcurrentPerformanceBenchmark()
        testCachePerformanceBenchmark()
        
        // è®¡ç®—ç»¼åˆè¯„åˆ†
        val overallScore = calculateOverallScore()
        
        Log.d(TAG, "ç»¼åˆæ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœ:")
        Log.d(TAG, "  åŸºå‡†æµ‹è¯•æ•°é‡: ${benchmarkResults.size}")
        Log.d(TAG, "  è¾¾æ ‡åŸºå‡†æ•°é‡: ${benchmarkResults.count { it.isTargetMet() }}")
        Log.d(TAG, "  ç»¼åˆè¯„åˆ†: ${String.format("%.1f", overallScore)}")
        
        // è¾“å‡ºè¯¦ç»†åŸºå‡†ç»“æœ
        benchmarkResults.forEach { benchmark ->
            val summary = benchmark.getSummary()
            Log.d(TAG, "  ${summary["name"]}: ${summary["current_value"]} ${summary["unit"]} " +
                    "(ç›®æ ‡: ${summary["target_value"]} ${summary["unit"]}, " +
                    "è¾¾æˆç‡: ${summary["achievement_rate"]}, " +
                    "è¾¾æ ‡: ${summary["target_met"]})")
        }
        
        // è®°å½•ç»¼åˆåŸºå‡†
        benchmarkResults.add(
            PerformanceBenchmark(
                name = "ç»¼åˆæ€§èƒ½è¯„åˆ†",
                category = "ç»¼åˆæ€§èƒ½",
                targetValue = 80.0, // ç›®æ ‡80åˆ†
                currentValue = overallScore,
                unit = "åˆ†",
                direction = BenchmarkDirection.HIGHER_IS_BETTER
            )
        )
        
        // æ€§èƒ½æ–­è¨€
        assertTrue("ç»¼åˆæ€§èƒ½è¯„åˆ†åº”å¤§äº70åˆ†", overallScore > 70.0)
        assertTrue("è‡³å°‘80%çš„åŸºå‡†åº”è¾¾æ ‡", 
            benchmarkResults.count { it.isTargetMet() }.toDouble() / benchmarkResults.size > 0.8)
        
        Log.d(TAG, "âœ… ç»¼åˆæ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ")
    }
    
    /**
     * ğŸ“Š è®¡ç®—ç»¼åˆè¯„åˆ†
     */
    private fun calculateOverallScore(): Double {
        if (benchmarkResults.isEmpty()) return 0.0
        
        val totalScore = benchmarkResults.sumOf { benchmark ->
            benchmark.getAchievementRate() * 100.0
        }
        
        return totalScore / benchmarkResults.size
    }
    
    /**
     * ğŸ“Š è·å–åŸºå‡†æµ‹è¯•ç»“æœ
     */
    fun getBenchmarkResults(): List<PerformanceBenchmark> {
        return benchmarkResults.toList()
    }
}
