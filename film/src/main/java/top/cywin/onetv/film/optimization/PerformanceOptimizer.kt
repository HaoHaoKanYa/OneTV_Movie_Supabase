package top.cywin.onetv.film.optimization

import android.content.Context
import android.util.Log
import kotlinx.coroutines.*
import kotlinx.coroutines.flow.MutableSharedFlow
import kotlinx.coroutines.flow.SharedFlow
import kotlinx.coroutines.flow.asSharedFlow
import top.cywin.onetv.film.catvod.SpiderManager
import top.cywin.onetv.film.concurrent.ConcurrentManager
import top.cywin.onetv.film.cache.CacheManager
import top.cywin.onetv.film.network.NetworkClient
import top.cywin.onetv.film.utils.DateTimeUtils
import java.util.concurrent.atomic.AtomicLong
import java.util.concurrent.ConcurrentHashMap

/**
 * æ€§èƒ½ä¼˜åŒ–å™¨
 * 
 * åŸºäº FongMi/TV çš„æ€§èƒ½ä¼˜åŒ–ç³»ç»Ÿå®ç°
 * æä¾›è‡ªåŠ¨æ€§èƒ½ç›‘æ§ã€åˆ†æå’Œä¼˜åŒ–å»ºè®®
 * 
 * åŠŸèƒ½ï¼š
 * - æ€§èƒ½ç›‘æ§å’Œåˆ†æ
 * - è‡ªåŠ¨ä¼˜åŒ–å»ºè®®
 * - èµ„æºä½¿ç”¨ä¼˜åŒ–
 * - å†…å­˜ç®¡ç†ä¼˜åŒ–
 * - ç½‘ç»œæ€§èƒ½ä¼˜åŒ–
 * - ç¼“å­˜ç­–ç•¥ä¼˜åŒ–
 * - å¹¶å‘æ€§èƒ½ä¼˜åŒ–
 * 
 * @author OneTV Team
 * @since 2025-07-12
 */
class PerformanceOptimizer(
    private val context: Context,
    private val spiderManager: SpiderManager
) {
    
    companion object {
        private const val TAG = "ONETV_FILM_PERFORMANCE_OPTIMIZER"
        private const val MONITORING_INTERVAL = 60000L // 1åˆ†é’Ÿ
        private const val OPTIMIZATION_INTERVAL = 300000L // 5åˆ†é’Ÿ
        private const val MEMORY_THRESHOLD = 0.8f // 80%
        private const val CPU_THRESHOLD = 0.7f // 70%
        private const val NETWORK_LATENCY_THRESHOLD = 2000L // 2ç§’
    }
    
    // ç»„ä»¶å¼•ç”¨
    private val concurrentManager = spiderManager.getConcurrentManager()
    private val cacheManager = spiderManager.getCacheManager()
    private val networkClient = spiderManager.getNetworkClient()
    
    // åç¨‹ä½œç”¨åŸŸ
    private val scope = CoroutineScope(Dispatchers.IO + SupervisorJob())
    
    // æ€§èƒ½ç›‘æ§
    private val performanceMonitor = PerformanceMonitor()
    private val optimizationEngine = OptimizationEngine()
    
    // äº‹ä»¶æµ
    private val _events = MutableSharedFlow<OptimizationEvent>()
    val events: SharedFlow<OptimizationEvent> = _events.asSharedFlow()
    
    // ç›‘æ§ä»»åŠ¡
    private var monitoringJob: Job? = null
    private var optimizationJob: Job? = null
    
    // ä¼˜åŒ–ç»Ÿè®¡
    private val optimizationStats = OptimizationStatistics()
    
    init {
        startMonitoring()
        startOptimization()
        Log.d(TAG, "ğŸ—ï¸ æ€§èƒ½ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
    }
    
    /**
     * ğŸš€ å¯åŠ¨æ€§èƒ½ç›‘æ§
     */
    private fun startMonitoring() {
        monitoringJob = scope.launch {
            while (isActive) {
                try {
                    performanceMonitor.collectMetrics()
                    delay(MONITORING_INTERVAL)
                } catch (e: Exception) {
                    Log.e(TAG, "âŒ æ€§èƒ½ç›‘æ§å¼‚å¸¸", e)
                }
            }
        }
        
        Log.d(TAG, "ğŸš€ æ€§èƒ½ç›‘æ§å·²å¯åŠ¨")
    }
    
    /**
     * ğŸš€ å¯åŠ¨è‡ªåŠ¨ä¼˜åŒ–
     */
    private fun startOptimization() {
        optimizationJob = scope.launch {
            while (isActive) {
                try {
                    performAutoOptimization()
                    delay(OPTIMIZATION_INTERVAL)
                } catch (e: Exception) {
                    Log.e(TAG, "âŒ è‡ªåŠ¨ä¼˜åŒ–å¼‚å¸¸", e)
                }
            }
        }
        
        Log.d(TAG, "ğŸš€ è‡ªåŠ¨ä¼˜åŒ–å·²å¯åŠ¨")
    }
    
    /**
     * ğŸ” æ‰§è¡Œæ€§èƒ½åˆ†æ
     */
    suspend fun analyzePerformance(): PerformanceReport {
        Log.d(TAG, "ğŸ” æ‰§è¡Œæ€§èƒ½åˆ†æ...")
        
        val startTime = System.currentTimeMillis()
        
        try {
            // æ”¶é›†å½“å‰æ€§èƒ½æŒ‡æ ‡
            val metrics = performanceMonitor.getCurrentMetrics()
            
            // åˆ†æå„ä¸ªç»„ä»¶æ€§èƒ½
            val memoryAnalysis = analyzeMemoryUsage()
            val cpuAnalysis = analyzeCpuUsage()
            val networkAnalysis = analyzeNetworkPerformance()
            val cacheAnalysis = analyzeCachePerformance()
            val concurrentAnalysis = analyzeConcurrentPerformance()
            
            // ç”Ÿæˆä¼˜åŒ–å»ºè®®
            val recommendations = optimizationEngine.generateRecommendations(
                memoryAnalysis, cpuAnalysis, networkAnalysis, cacheAnalysis, concurrentAnalysis
            )
            
            // è®¡ç®—æ€§èƒ½è¯„åˆ†
            val performanceScore = calculatePerformanceScore(
                memoryAnalysis, cpuAnalysis, networkAnalysis, cacheAnalysis, concurrentAnalysis
            )
            
            val report = PerformanceReport(
                timestamp = System.currentTimeMillis(),
                performanceScore = performanceScore,
                memoryAnalysis = memoryAnalysis,
                cpuAnalysis = cpuAnalysis,
                networkAnalysis = networkAnalysis,
                cacheAnalysis = cacheAnalysis,
                concurrentAnalysis = concurrentAnalysis,
                recommendations = recommendations,
                metrics = metrics
            )
            
            val duration = System.currentTimeMillis() - startTime
            optimizationStats.recordAnalysis(duration, recommendations.size)
            
            _events.emit(OptimizationEvent.AnalysisCompleted(report))
            
            Log.d(TAG, "âœ… æ€§èƒ½åˆ†æå®Œæˆï¼Œè¯„åˆ†: $performanceScore, è€—æ—¶: ${duration}ms")
            
            return report
            
        } catch (e: Exception) {
            Log.e(TAG, "âŒ æ€§èƒ½åˆ†æå¤±è´¥", e)
            throw e
        }
    }
    
    /**
     * ğŸ”§ æ‰§è¡Œè‡ªåŠ¨ä¼˜åŒ–
     */
    private suspend fun performAutoOptimization() {
        Log.d(TAG, "ğŸ”§ æ‰§è¡Œè‡ªåŠ¨ä¼˜åŒ–...")
        
        try {
            val report = analyzePerformance()
            val appliedOptimizations = mutableListOf<String>()
            
            // åº”ç”¨è‡ªåŠ¨ä¼˜åŒ–å»ºè®®
            report.recommendations.forEach { recommendation ->
                if (recommendation.autoApplicable) {
                    try {
                        applyOptimization(recommendation)
                        appliedOptimizations.add(recommendation.type)
                        Log.d(TAG, "âœ… åº”ç”¨ä¼˜åŒ–: ${recommendation.type}")
                    } catch (e: Exception) {
                        Log.e(TAG, "âŒ åº”ç”¨ä¼˜åŒ–å¤±è´¥: ${recommendation.type}", e)
                    }
                }
            }
            
            if (appliedOptimizations.isNotEmpty()) {
                optimizationStats.recordOptimization(appliedOptimizations.size)
                _events.emit(OptimizationEvent.OptimizationApplied(appliedOptimizations))
                
                Log.d(TAG, "ğŸ”§ è‡ªåŠ¨ä¼˜åŒ–å®Œæˆï¼Œåº”ç”¨æ•°: ${appliedOptimizations.size}")
            }
            
        } catch (e: Exception) {
            Log.e(TAG, "âŒ è‡ªåŠ¨ä¼˜åŒ–å¤±è´¥", e)
        }
    }
    
    /**
     * ğŸ§  åˆ†æå†…å­˜ä½¿ç”¨
     */
    private fun analyzeMemoryUsage(): MemoryAnalysis {
        val runtime = Runtime.getRuntime()
        val totalMemory = runtime.totalMemory()
        val freeMemory = runtime.freeMemory()
        val usedMemory = totalMemory - freeMemory
        val maxMemory = runtime.maxMemory()
        
        val usageRatio = usedMemory.toFloat() / maxMemory.toFloat()
        val availableMemory = maxMemory - usedMemory
        
        val status = when {
            usageRatio > 0.9f -> MemoryStatus.CRITICAL
            usageRatio > 0.8f -> MemoryStatus.HIGH
            usageRatio > 0.6f -> MemoryStatus.MODERATE
            else -> MemoryStatus.NORMAL
        }
        
        return MemoryAnalysis(
            totalMemory = totalMemory,
            usedMemory = usedMemory,
            freeMemory = freeMemory,
            maxMemory = maxMemory,
            availableMemory = availableMemory,
            usageRatio = usageRatio,
            status = status
        )
    }
    
    /**
     * âš¡ åˆ†æCPUä½¿ç”¨
     */
    private fun analyzeCpuUsage(): CpuAnalysis {
        // è·å–çº¿ç¨‹æ± çŠ¶æ€
        val threadPoolStatus = concurrentManager.getThreadPoolStatus()
        val totalThreads = threadPoolStatus.values.sumOf { 
            (it["current_pool_size"] as? Int) ?: 0 
        }
        val activeThreads = threadPoolStatus.values.sumOf { 
            (it["active_count"] as? Int) ?: 0 
        }
        
        val cpuCores = Runtime.getRuntime().availableProcessors()
        val threadUtilization = if (totalThreads > 0) activeThreads.toFloat() / totalThreads.toFloat() else 0f
        
        val status = when {
            threadUtilization > 0.9f -> CpuStatus.HIGH
            threadUtilization > 0.7f -> CpuStatus.MODERATE
            else -> CpuStatus.NORMAL
        }
        
        return CpuAnalysis(
            cpuCores = cpuCores,
            totalThreads = totalThreads,
            activeThreads = activeThreads,
            threadUtilization = threadUtilization,
            status = status
        )
    }
    
    /**
     * ğŸŒ åˆ†æç½‘ç»œæ€§èƒ½
     */
    private fun analyzeNetworkPerformance(): NetworkAnalysis {
        val networkStats = networkClient.getStats()
        
        val totalRequests = (networkStats["total_requests"] as? Long) ?: 0L
        val successRequests = (networkStats["success_requests"] as? Long) ?: 0L
        val failedRequests = (networkStats["failed_requests"] as? Long) ?: 0L
        val averageLatency = (networkStats["average_latency"] as? Long) ?: 0L
        
        val successRate = if (totalRequests > 0) successRequests.toFloat() / totalRequests.toFloat() else 0f
        val errorRate = if (totalRequests > 0) failedRequests.toFloat() / totalRequests.toFloat() else 0f
        
        val status = when {
            errorRate > 0.1f || averageLatency > NETWORK_LATENCY_THRESHOLD -> NetworkStatus.POOR
            errorRate > 0.05f || averageLatency > 1000L -> NetworkStatus.MODERATE
            else -> NetworkStatus.GOOD
        }
        
        return NetworkAnalysis(
            totalRequests = totalRequests,
            successRequests = successRequests,
            failedRequests = failedRequests,
            successRate = successRate,
            errorRate = errorRate,
            averageLatency = averageLatency,
            status = status
        )
    }
    
    /**
     * ğŸ—„ï¸ åˆ†æç¼“å­˜æ€§èƒ½
     */
    private fun analyzeCachePerformance(): CacheAnalysis {
        val cacheStats = cacheManager.getStats()
        
        val hitCount = (cacheStats["hit_count"] as? Long) ?: 0L
        val missCount = (cacheStats["miss_count"] as? Long) ?: 0L
        val hitRate = (cacheStats["hit_rate"] as? Double) ?: 0.0
        val memoryUsage = (cacheStats["memory_size_bytes"] as? Long) ?: 0L
        val diskUsage = (cacheStats["disk_size_bytes"] as? Long) ?: 0L
        
        val status = when {
            hitRate < 0.5 -> CacheStatus.POOR
            hitRate < 0.7 -> CacheStatus.MODERATE
            else -> CacheStatus.GOOD
        }
        
        return CacheAnalysis(
            hitCount = hitCount,
            missCount = missCount,
            hitRate = hitRate,
            memoryUsage = memoryUsage,
            diskUsage = diskUsage,
            status = status
        )
    }
    
    /**
     * âš¡ åˆ†æå¹¶å‘æ€§èƒ½
     */
    private fun analyzeConcurrentPerformance(): ConcurrentAnalysis {
        val concurrentStats = concurrentManager.getConcurrentStats()
        
        val totalTasks = (concurrentStats["total_tasks"] as? Long) ?: 0L
        val completedTasks = (concurrentStats["completed_tasks"] as? Long) ?: 0L
        val failedTasks = (concurrentStats["failed_tasks"] as? Long) ?: 0L
        val averageExecutionTime = (concurrentStats["average_execution_time"] as? Long) ?: 0L
        
        val successRate = if (totalTasks > 0) completedTasks.toFloat() / totalTasks.toFloat() else 0f
        val failureRate = if (totalTasks > 0) failedTasks.toFloat() / totalTasks.toFloat() else 0f
        
        val status = when {
            failureRate > 0.1f || averageExecutionTime > 5000L -> ConcurrentStatus.POOR
            failureRate > 0.05f || averageExecutionTime > 2000L -> ConcurrentStatus.MODERATE
            else -> ConcurrentStatus.GOOD
        }
        
        return ConcurrentAnalysis(
            totalTasks = totalTasks,
            completedTasks = completedTasks,
            failedTasks = failedTasks,
            successRate = successRate,
            failureRate = failureRate,
            averageExecutionTime = averageExecutionTime,
            status = status
        )
    }
    
    /**
     * ğŸ“Š è®¡ç®—æ€§èƒ½è¯„åˆ†
     */
    private fun calculatePerformanceScore(
        memoryAnalysis: MemoryAnalysis,
        cpuAnalysis: CpuAnalysis,
        networkAnalysis: NetworkAnalysis,
        cacheAnalysis: CacheAnalysis,
        concurrentAnalysis: ConcurrentAnalysis
    ): Float {
        val memoryScore = when (memoryAnalysis.status) {
            MemoryStatus.NORMAL -> 100f
            MemoryStatus.MODERATE -> 80f
            MemoryStatus.HIGH -> 60f
            MemoryStatus.CRITICAL -> 30f
        }
        
        val cpuScore = when (cpuAnalysis.status) {
            CpuStatus.NORMAL -> 100f
            CpuStatus.MODERATE -> 70f
            CpuStatus.HIGH -> 40f
        }
        
        val networkScore = when (networkAnalysis.status) {
            NetworkStatus.GOOD -> 100f
            NetworkStatus.MODERATE -> 70f
            NetworkStatus.POOR -> 40f
        }
        
        val cacheScore = when (cacheAnalysis.status) {
            CacheStatus.GOOD -> 100f
            CacheStatus.MODERATE -> 70f
            CacheStatus.POOR -> 40f
        }
        
        val concurrentScore = when (concurrentAnalysis.status) {
            ConcurrentStatus.GOOD -> 100f
            ConcurrentStatus.MODERATE -> 70f
            ConcurrentStatus.POOR -> 40f
        }
        
        // åŠ æƒå¹³å‡
        return (memoryScore * 0.25f + cpuScore * 0.2f + networkScore * 0.2f + 
                cacheScore * 0.2f + concurrentScore * 0.15f)
    }
    
    /**
     * ğŸ”§ åº”ç”¨ä¼˜åŒ–
     */
    private suspend fun applyOptimization(recommendation: OptimizationRecommendation) {
        when (recommendation.type) {
            "memory_cleanup" -> {
                System.gc()
                cacheManager.clear()
            }
            "cache_optimization" -> {
                // åº”ç”¨ç¼“å­˜ä¼˜åŒ–
            }
            "thread_pool_adjustment" -> {
                // è°ƒæ•´çº¿ç¨‹æ± é…ç½®
            }
            "network_optimization" -> {
                // åº”ç”¨ç½‘ç»œä¼˜åŒ–
            }
        }
    }
    
    /**
     * ğŸ“Š è·å–ä¼˜åŒ–ç»Ÿè®¡
     */
    fun getOptimizationStats(): Map<String, Any> {
        return optimizationStats.getStats()
    }
    
    /**
     * ğŸ›‘ å…³é—­ä¼˜åŒ–å™¨
     */
    fun shutdown() {
        monitoringJob?.cancel()
        optimizationJob?.cancel()
        scope.cancel()
        
        Log.d(TAG, "ğŸ›‘ æ€§èƒ½ä¼˜åŒ–å™¨å·²å…³é—­")
    }
}

/**
 * æ€§èƒ½ç›‘æ§å™¨
 */
class PerformanceMonitor {
    private val metrics = ConcurrentHashMap<String, Any>()
    
    fun collectMetrics() {
        val runtime = Runtime.getRuntime()
        
        metrics["timestamp"] = System.currentTimeMillis()
        metrics["total_memory"] = runtime.totalMemory()
        metrics["free_memory"] = runtime.freeMemory()
        metrics["max_memory"] = runtime.maxMemory()
        metrics["used_memory"] = runtime.totalMemory() - runtime.freeMemory()
        metrics["available_processors"] = runtime.availableProcessors()
    }
    
    fun getCurrentMetrics(): Map<String, Any> = metrics.toMap()
}

/**
 * ä¼˜åŒ–å¼•æ“
 */
class OptimizationEngine {
    
    fun generateRecommendations(
        memoryAnalysis: MemoryAnalysis,
        cpuAnalysis: CpuAnalysis,
        networkAnalysis: NetworkAnalysis,
        cacheAnalysis: CacheAnalysis,
        concurrentAnalysis: ConcurrentAnalysis
    ): List<OptimizationRecommendation> {
        val recommendations = mutableListOf<OptimizationRecommendation>()
        
        // å†…å­˜ä¼˜åŒ–å»ºè®®
        if (memoryAnalysis.status == MemoryStatus.HIGH || memoryAnalysis.status == MemoryStatus.CRITICAL) {
            recommendations.add(
                OptimizationRecommendation(
                    type = "memory_cleanup",
                    priority = Priority.HIGH,
                    description = "å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®æ¸…ç†ç¼“å­˜å’Œæ‰§è¡Œåƒåœ¾å›æ”¶",
                    autoApplicable = true,
                    impact = "å‡å°‘å†…å­˜ä½¿ç”¨ï¼Œæå‡åº”ç”¨ç¨³å®šæ€§"
                )
            )
        }
        
        // ç¼“å­˜ä¼˜åŒ–å»ºè®®
        if (cacheAnalysis.status == CacheStatus.POOR) {
            recommendations.add(
                OptimizationRecommendation(
                    type = "cache_optimization",
                    priority = Priority.MEDIUM,
                    description = "ç¼“å­˜å‘½ä¸­ç‡è¾ƒä½ï¼Œå»ºè®®è°ƒæ•´ç¼“å­˜ç­–ç•¥",
                    autoApplicable = false,
                    impact = "æå‡æ•°æ®è®¿é—®é€Ÿåº¦ï¼Œå‡å°‘ç½‘ç»œè¯·æ±‚"
                )
            )
        }
        
        // ç½‘ç»œä¼˜åŒ–å»ºè®®
        if (networkAnalysis.status == NetworkStatus.POOR) {
            recommendations.add(
                OptimizationRecommendation(
                    type = "network_optimization",
                    priority = Priority.HIGH,
                    description = "ç½‘ç»œæ€§èƒ½è¾ƒå·®ï¼Œå»ºè®®ä¼˜åŒ–ç½‘ç»œé…ç½®",
                    autoApplicable = false,
                    impact = "æå‡ç½‘ç»œè¯·æ±‚æˆåŠŸç‡å’Œå“åº”é€Ÿåº¦"
                )
            )
        }
        
        // å¹¶å‘ä¼˜åŒ–å»ºè®®
        if (concurrentAnalysis.status == ConcurrentStatus.POOR) {
            recommendations.add(
                OptimizationRecommendation(
                    type = "concurrent_optimization",
                    priority = Priority.MEDIUM,
                    description = "å¹¶å‘ä»»åŠ¡å¤±è´¥ç‡è¾ƒé«˜ï¼Œå»ºè®®è°ƒæ•´å¹¶å‘é…ç½®",
                    autoApplicable = false,
                    impact = "æå‡ä»»åŠ¡æ‰§è¡ŒæˆåŠŸç‡å’Œæ•ˆç‡"
                )
            )
        }
        
        return recommendations
    }
}
